{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sonic-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-design",
   "metadata": {},
   "source": [
    "## RCNN + Grabcut method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-right",
   "metadata": {},
   "source": [
    "### Load pretrained labels, weights and model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fresh-silver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model.\n"
     ]
    }
   ],
   "source": [
    "label = os.path.join(\"helper\", \"object_detection_classes_coco.txt\")\n",
    "LABELS = open(label).read().strip().split(\"\\n\")\n",
    "weightsPath = os.path.join(\"helper\", \"frozen_inference_graph.pb\")\n",
    "configPath = os.path.join(\"helper\",\"mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\")\n",
    "print(\"Loaded model.\")\n",
    "net = cv2.dnn.readNetFromTensorflow(weightsPath, configPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sensitive-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a list of colors to represent each possible class label\n",
    "np.random.seed(42)\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-hacker",
   "metadata": {},
   "source": [
    "### Read input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dynamic-sleeve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(\"Image1.jpg\")\n",
    "cv2.imshow(\"Input\", image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-wrong",
   "metadata": {},
   "source": [
    "### Code to calculate Dice score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "daily-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dice_coefficient(mask_gt, mask_pred):\n",
    "  volume_sum = mask_gt.sum() + mask_pred.sum()\n",
    "  if volume_sum == 0:\n",
    "    return np.NaN\n",
    "  volume_intersect = (mask_gt & mask_pred).sum()\n",
    "  return 2*volume_intersect / volume_sum "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-tulsa",
   "metadata": {},
   "source": [
    "### Do predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "yellow-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = cv2.dnn.blobFromImage(image, swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "(boxes, masks) = net.forward([\"detection_out_final\", \"detection_masks\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-alloy",
   "metadata": {},
   "source": [
    "##### Threshold value is obtained by experiments, more threshold tighter requires more confidence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "smoking-drove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class detected is cow\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.05\n",
    "outputMask = None\n",
    "for i in range(0, boxes.shape[2]):\n",
    "    classID = int(boxes[0, 0, i, 1])\n",
    "    confidence = boxes[0, 0, i, 2]\n",
    "    \n",
    "    if confidence > threshold:\n",
    "        print(\"Class detected is {}\".format(LABELS[classID]))\n",
    "        \n",
    "        (H, W) = image.shape[:2]\n",
    "        box = boxes[0, 0, i, 3:7] * np.array([W, H, W, H])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "        boxW = endX - startX\n",
    "        boxH = endY - startY\n",
    "        mask = masks[i, classID]\n",
    "        mask = cv2.resize(mask, (boxW, boxH),  interpolation=cv2.INTER_CUBIC)\n",
    "        mask = (mask > threshold).astype(\"uint8\") * 255\n",
    "        \n",
    "        rcnnMask = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
    "        rcnnMask[startY:endY, startX:endX] = mask\n",
    "        \n",
    "        \n",
    "        \n",
    "        cv2.imshow(\"R-CNN Mask Intermediate result\", rcnnMask)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        temp = rcnnMask.copy()\n",
    "        temp[temp > 0] = cv2.GC_PR_FGD\n",
    "        temp[temp == 0] = cv2.GC_BGD\n",
    "        \n",
    "        # Apply grab cut now\n",
    "        fgModel = np.zeros((1, 65), dtype=\"float\")\n",
    "        bgModel = np.zeros((1, 65), dtype=\"float\")\n",
    "        (temp, bgModel, fgModel) = cv2.grabCut(image, temp, None, bgModel, fgModel, iterCount=5, mode=cv2.GC_INIT_WITH_MASK)\n",
    "        \n",
    "        outputMask = np.where((temp == cv2.GC_BGD) | (temp == cv2.GC_PR_BGD), 0, 1)\n",
    "        outputMask = (outputMask * 255).astype(\"uint8\")\n",
    "        #cv2.imwrite(\"Image2_seg.png\", outputMask)\n",
    "        cv2.imshow(\"GrabCut Mask\", outputMask)\n",
    "        cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-castle",
   "metadata": {},
   "source": [
    "## Below is code is for YOLO + grabcut method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "administrative-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectObject(image):\n",
    "    yolo_config='yolov3.cfg'\n",
    "    if not os.path.isfile(yolo_config):\n",
    "        url='https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg'\n",
    "        r=requests.get(url)\n",
    "        with open(yolo_config,'wb') as f:\n",
    "            f.write(r.content)\n",
    "    yolo_weights = 'yolov3.weights'\n",
    "    if not os.path.isfile(yolo_weights):\n",
    "        url = 'https://pjreddie.com/media/files/yolov3.weights'\n",
    "        r = requests.get(url)\n",
    "        with open(yolo_weights, 'wb') as f:\n",
    "            f.write(r.content)        \n",
    "    classes_file='coco.names'\n",
    "    if not os.path.isfile(classes_file):\n",
    "        url='https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names'\n",
    "        r=requests.get(url)\n",
    "        with open(classes_file,'wb') as f:\n",
    "            f.write(r.content)\n",
    "    \n",
    "    with open(classes_file,'r') as f:\n",
    "        classes=[line.strip() for line in f.readlines()]\n",
    "\n",
    "   \n",
    "    blob=cv2.dnn.blobFromImage(image,1/255,(416,416),(0,0,0),True,crop=False)\n",
    "    net=cv2.dnn.readNet(yolo_weights,yolo_config)\n",
    "    net.setInput(blob)\n",
    "    layer_names=net.getLayerNames()\n",
    "    output_layers=[layer_names[i[0]-1] for i in net.getUnconnectedOutLayers()]\n",
    "    outs=net.forward(output_layers)\n",
    "    class_ids= list()\n",
    "    confidences= list()\n",
    "    boxes= list()\n",
    "\n",
    "    for out in outs:\n",
    "        # iterate over anchor boxes for human class\n",
    "        for detection in out:\n",
    "            #bounding box\n",
    "            center_x=int(detection[0] * image.shape[1])\n",
    "            center_y=int(detection[1] * image.shape[0])\n",
    "            w=int(detection[2] * image.shape[1])\n",
    "            h=int(detection[3] * image.shape[0])\n",
    "            x=center_x - w // 2\n",
    "            y=center_y - h // 2\n",
    "            boxes.append([x,y,w,h])\n",
    "            #class\n",
    "            class_id=np.argmax(detection[5:])\n",
    "            class_ids.append(class_id)\n",
    "            confidence=detection[4]\n",
    "            confidences.append(float(confidence))\n",
    "    #non-max supression\n",
    "    ids=cv2.dnn.NMSBoxes(boxes,confidences,score_threshold=0.2,nms_threshold=0.9)\n",
    "    \n",
    "    colors= np.random.uniform(0,255,size=(len(classes),3))\n",
    "    for i in ids:\n",
    "        i=i[0]\n",
    "        x,y,w,h=boxes[i]\n",
    "        class_id=class_ids[i]\n",
    "        color=colors[class_id]\n",
    "        return (x, y, x+h, y+w)\n",
    "        \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unusual-night",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 58, 279, 328)\n"
     ]
    }
   ],
   "source": [
    "rec = detectObject(image)\n",
    "\n",
    "# If object not found then use complete image.\n",
    "if rec == None:\n",
    "    rec = (0, 0, image.shape[0], image.shape[1])\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-cache",
   "metadata": {},
   "source": [
    "### Apply grab cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accessory-daily",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GrabCut took 0.89 seconds\n"
     ]
    }
   ],
   "source": [
    "mask = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
    "fgModel = np.zeros((1, 65), dtype=\"float\")\n",
    "bgModel = np.zeros((1, 65), dtype=\"float\")\n",
    "# apply GrabCut using the the bounding box segmentation method\n",
    "start = time.time()\n",
    "(mask, bgModel, fgModel) = cv2.grabCut(image, mask, rec, bgModel,fgModel, iterCount=5, mode=cv2.GC_INIT_WITH_RECT)\n",
    "end = time.time()\n",
    "print(\"GrabCut took {:.2f} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-nylon",
   "metadata": {},
   "source": [
    "### Extract foreground mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "confused-delight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = (\n",
    "    (\"Definite Background\", cv2.GC_BGD),\n",
    "    (\"Probable Background\", cv2.GC_PR_BGD),\n",
    "    (\"Definite Foreground\", cv2.GC_FGD),\n",
    "    (\"Probable Foreground\", cv2.GC_PR_FGD),\n",
    ")\n",
    "outputMask = (mask == cv2.GC_PR_FGD).astype(\"uint8\") * 255\n",
    "#cv2.imwrite(\"Image1_seg.png\", outputMask)\n",
    "cv2.imshow(\"Probable Foreground\", outputMask)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-williams",
   "metadata": {},
   "source": [
    "### Run  below cell to calculate dice score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eastern-dinner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9615456890513692"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mask_gt = cv2.imread(\"Image1_GT.png\")\n",
    "image_pred = cv2.imread(\"Image1_seg.png\")\n",
    "compute_dice_coefficient(mask_gt, image_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-accountability",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
